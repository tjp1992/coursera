{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "\n",
    "The following notebook summarizes the Second part of [Machine Learning Specialization](https://www.coursera.org/learn/advanced-learning-algorithms?courseSlug=advanced-learning-algorithms&showOnboardingModal=checkAndRedirect&specialization=machine-learning-introduction) which deals with *Neural Networks* and Training Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network \n",
    "\n",
    "Neural network is a model which comprises of multiple layers to imitate the structure of human brain cells. Layers include *Input Layer*, *Hidden Layer* and *Output Layer*. \n",
    "\n",
    "Depending on the layer structure layers can be connected *Dense*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer\n",
    "\n",
    "A layer composes of multiple neurons that is grouped as one layer. Each layer ouputs an *activation values* which will be fed into the next layer, which ultimately will predict/forecast the value(regression) or probability(logistic regression) depending on the purpose of the model.\n",
    "\n",
    "\n",
    "The Following equation demonstrates the equation of a single *neuron* of a *hidden layer* what is doing *logistic regression*\n",
    "\n",
    "$$\n",
    "a_{j}^{l} = g(\\vec{w}_{j}^{[l]} * \\vec{a}^{[l-1]} + b_{j}^{[l]})\n",
    "$$\n",
    "\n",
    "$a_{j}^{l}$ denotes the output value of the *neuron($_{j}$) of current layer($^{l}$)* which will be subsequently used as input for the next layer and $\\vec{a^{[l-1]}}$ denotes the output vector from the previous layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data in Tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200,  17]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[200,17]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200],\n",
       "       [ 17]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[200],[17]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200,  17])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([200,17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples above displays how numpy arrays can be created, the first two are 2D arrays, but the last creates a 1D vector which has different shapes compared to the other examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "x = np.array([\n",
    "    [200.0,17.0],\n",
    "    [20.0,170.0]\n",
    "])\n",
    "y = np.array([1,0])\n",
    "layer_1 = Dense(units=3, activation='sigmoid')\n",
    "# a1 = layer_1(x)\n",
    "layer_2 = Dense(units=1, activation='sigmoid')\n",
    "# a2 = layer_2(a1)\n",
    "model = Sequential([layer_1, layer_2])\n",
    "\n",
    "# Example of compiling model to fit data\n",
    "model.compile(...)\n",
    "model.fit(x,y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is a simple implementation of using tensorflow library to create a simple model. However, in order to properly debug a model, one needs to have a general idea of how the model is being compiled and trained under the hood. The code below demonstrates the basic flow of how the tensorflow library is fitting the data to it's model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code is used to create a single neuron in layers\n",
    "def dense(a_in, W, b, g):\n",
    "    units = W.shape[1]\n",
    "    a_out=np.zeros(units)\n",
    "    for j in range(units):\n",
    "        w = W[:,j]\n",
    "        z = np.dot(w,a_in) + b[j]\n",
    "        a_out[j] = g(z)\n",
    "    return a_out\n",
    "\n",
    "# Function below creates a model with one layer of 4 neurons that will take in vector x to do\n",
    "# logistic regression\n",
    "\n",
    "def sequential(x):\n",
    "    a1 = dense(x, W1, b1)\n",
    "    a2 = dense(a1, W2, b2)\n",
    "    a3 = dense(a2, W3, b3)\n",
    "    a4 = dense(a3, W4, b4)\n",
    "    f_x = a4\n",
    "    return f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('lewagon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3409ef4a337282d13679ec96c667699dc5fb30c5ff7a8068d7e26a8f562e91ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
